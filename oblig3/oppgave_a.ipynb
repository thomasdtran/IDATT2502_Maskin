{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9326b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = tensor(0.9461)\n",
      "accuracy = tensor(0.9624)\n",
      "accuracy = tensor(0.9707)\n",
      "accuracy = tensor(0.9741)\n",
      "accuracy = tensor(0.9770)\n",
      "accuracy = tensor(0.9785)\n",
      "accuracy = tensor(0.9789)\n",
      "accuracy = tensor(0.9792)\n",
      "accuracy = tensor(0.9795)\n",
      "accuracy = tensor(0.9794)\n",
      "accuracy = tensor(0.9798)\n",
      "accuracy = tensor(0.9796)\n",
      "accuracy = tensor(0.9796)\n",
      "accuracy = tensor(0.9794)\n",
      "accuracy = tensor(0.9800)\n",
      "accuracy = tensor(0.9795)\n",
      "accuracy = tensor(0.9792)\n",
      "accuracy = tensor(0.9785)\n",
      "accuracy = tensor(0.9785)\n",
      "accuracy = tensor(0.9784)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ta utgangspunkt i nn.py eller nn_sequential.py i ntnu-tdat3025/cnn/mnist.\n",
    "Kjør først dette eksempelet og se hva accuracy modellen oppnår.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# Load observations from the mnist dataset. The observations are divided into a training set and a test set\n",
    "mnist_train = torchvision.datasets.MNIST('./data', train=True, download=True)\n",
    "x_train = mnist_train.data.reshape(-1, 1, 28, 28).float()  # torch.functional.nn.conv2d argument must include channels (1)\n",
    "y_train = torch.zeros((mnist_train.targets.shape[0], 10))  # Create output tensor\n",
    "y_train[torch.arange(mnist_train.targets.shape[0]), mnist_train.targets] = 1  # Populate output\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('./data', train=False, download=True)\n",
    "x_test = mnist_test.data.reshape(-1, 1, 28, 28).float()  # torch.functional.nn.conv2d argument must include channels (1)\n",
    "y_test = torch.zeros((mnist_test.targets.shape[0], 10))  # Create output tensor\n",
    "y_test[torch.arange(mnist_test.targets.shape[0]), mnist_test.targets] = 1  # Populate output\n",
    "\n",
    "# Normalization of inputs\n",
    "mean = x_train.mean()\n",
    "std = x_train.std()\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "# Divide training data into batches to speed up optimization\n",
    "batches = 600\n",
    "x_train_batches = torch.split(x_train, batches)\n",
    "y_train_batches = torch.split(y_train, batches)\n",
    "\n",
    "\n",
    "class ConvolutionalNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetworkModel, self).__init__()\n",
    "\n",
    "        # Model layers (includes initialized model variables):\n",
    "        self.conv = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dense = nn.Linear(32 * 14 * 14, 10)\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return self.dense(x.reshape(-1, 32 * 14 * 14))\n",
    "\n",
    "    # Predictor\n",
    "    def f(self, x):\n",
    "        print(self.logits(x).shape)\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    # Cross Entropy loss\n",
    "    def loss(self, x, y):\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))\n",
    "\n",
    "    # Accuracy\n",
    "    def accuracy(self, x, y):\n",
    "        return torch.mean(torch.eq(self.f(x).argmax(1), y.argmax(1)).float())\n",
    "\n",
    "\n",
    "model = ConvolutionalNeuralNetworkModel()\n",
    "\n",
    "# Optimize: adjust W and b to minimize loss using stochastic gradient descent\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "for epoch in range(20):\n",
    "    for batch in range(len(x_train_batches)):\n",
    "        model.loss(x_train_batches[batch], y_train_batches[batch]).backward()  # Compute loss gradients\n",
    "        optimizer.step()  # Perform optimization by adjusting W and b,\n",
    "        optimizer.zero_grad()  # Clear gradients for next step\n",
    "\n",
    "    print(\"accuracy = %s\" % model.accuracy(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4473242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/opt/homebrew/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = tensor(0.9741)\n",
      "accuracy = tensor(0.9836)\n",
      "accuracy = tensor(0.9844)\n",
      "accuracy = tensor(0.9852)\n",
      "accuracy = tensor(0.9845)\n",
      "accuracy = tensor(0.9833)\n",
      "accuracy = tensor(0.9845)\n",
      "accuracy = tensor(0.9842)\n",
      "accuracy = tensor(0.9837)\n",
      "accuracy = tensor(0.9856)\n",
      "accuracy = tensor(0.9837)\n",
      "accuracy = tensor(0.9865)\n",
      "accuracy = tensor(0.9860)\n",
      "accuracy = tensor(0.9865)\n",
      "accuracy = tensor(0.9823)\n",
      "accuracy = tensor(0.9837)\n",
      "accuracy = tensor(0.9826)\n",
      "accuracy = tensor(0.9799)\n",
      "accuracy = tensor(0.9855)\n",
      "accuracy = tensor(0.9865)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"a) Utvid modellen som vist nedenfor. Ca hva accuracy oppnår denne\n",
    "modellen?\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# Load observations from the mnist dataset. The observations are divided into a training set and a test set\n",
    "mnist_train = torchvision.datasets.MNIST('./data', train=True, download=True)\n",
    "x_train = mnist_train.data.reshape(-1, 1, 28, 28).float()  # torch.functional.nn.conv2d argument must include channels (1)\n",
    "y_train = torch.zeros((mnist_train.targets.shape[0], 10))  # Create output tensor\n",
    "y_train[torch.arange(mnist_train.targets.shape[0]), mnist_train.targets] = 1  # Populate output\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('./data', train=False, download=True)\n",
    "x_test = mnist_test.data.reshape(-1, 1, 28, 28).float()  # torch.functional.nn.conv2d argument must include channels (1)\n",
    "y_test = torch.zeros((mnist_test.targets.shape[0], 10))  # Create output tensor\n",
    "y_test[torch.arange(mnist_test.targets.shape[0]), mnist_test.targets] = 1  # Populate output\n",
    "\n",
    "# Normalization of inputs\n",
    "mean = x_train.mean()\n",
    "std = x_train.std()\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "# Divide training data into batches to speed up optimization\n",
    "batches = 600\n",
    "x_train_batches = torch.split(x_train, batches)\n",
    "y_train_batches = torch.split(y_train, batches)\n",
    "\n",
    "\n",
    "class ConvolutionalNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetworkModel, self).__init__()\n",
    "\n",
    "        # Model layers (includes initialized model variables):\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.dense = nn.Linear(64 * 7 * 7, 10)\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        return self.dense(x.reshape(-1, 64 * 7 * 7))\n",
    "\n",
    "    # Predictor\n",
    "    def f(self, x):\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    # Cross Entropy loss\n",
    "    def loss(self, x, y):\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))\n",
    "\n",
    "    # Accuracy\n",
    "    def accuracy(self, x, y):\n",
    "        return torch.mean(torch.eq(self.f(x).argmax(1), y.argmax(1)).float())\n",
    "\n",
    "\n",
    "model = ConvolutionalNeuralNetworkModel()\n",
    "\n",
    "# Optimize: adjust W and b to minimize loss using stochastic gradient descent\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "for epoch in range(20):\n",
    "    for batch in range(len(x_train_batches)):\n",
    "        model.loss(x_train_batches[batch], y_train_batches[batch]).backward()  # Compute loss gradients\n",
    "        optimizer.step()  # Perform optimization by adjusting W and b,\n",
    "        optimizer.zero_grad()  # Clear gradients for next step\n",
    "\n",
    "    print(\"accuracy = %s\" % model.accuracy(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403fb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
