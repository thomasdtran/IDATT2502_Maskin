{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19dc07d",
   "metadata": {},
   "source": [
    "# Oppgave b\n",
    "\n",
    "Tren modellen ulike ord (bruk fortsatt bokstavkoding som i oppgave a) <br>\n",
    "for emojis, for eksempel ‚Äúhat ‚Äù: , ‚Äúrat ‚Äú: , ‚Äúcat ‚Äú: , ‚Äúflat‚Äù: , <br>\n",
    "‚Äúmatt‚Äù: , ‚Äúcap ‚Äú: , ‚Äúson ‚Äù: . For √• kunne trene i batches er <br>\n",
    "ordene padded med mellomrom p√• slutten (hvis ordene er mindre enn\n",
    "makslengden).<br>\n",
    "Test deretter modellen p√• ord som ‚Äúrt ‚Äù og ‚Äúrats‚Äù, og se hvilken emoji\n",
    "du f√•r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f6e7bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat: üé©\n",
      "rat: üêÄ\n",
      "rt: üêÄ\n",
      "rats: üêÄ\n",
      "cap: üß¢\n",
      "üêÄ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LongShortTermMemoryModel(nn.Module):\n",
    "    def __init__(self, encoding_size, emoji_encoding_size):\n",
    "        super(LongShortTermMemoryModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(encoding_size, 128)  # 128 is the state size\n",
    "        self.dense = nn.Linear(128, emoji_encoding_size)  # 128 is the state size\n",
    "\n",
    "    def reset(self):  # Reset states prior to new input sequence\n",
    "        zero_state = torch.zeros(1, 1, 128)  # Shape: (number of layers, batch size, state size)\n",
    "        self.hidden_state = zero_state\n",
    "        self.cell_state = zero_state\n",
    "\n",
    "    def logits(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        out, (self.hidden_state, self.cell_state) = self.lstm(x, (self.hidden_state, self.cell_state))\n",
    "        return self.dense(out.reshape(-1, 128))\n",
    "\n",
    "    def f(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    def loss(self, x, y):  # x shape: (sequence length, batch size, encoding size), y shape: (sequence length, encoding size)\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))\n",
    "\n",
    "\n",
    "char_encodings = [\n",
    "    [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],# ' ' 0\n",
    "    [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],# 'a' 1\n",
    "    [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],# 't' 2\n",
    "    [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],# 'h' 3\n",
    "    [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],# 'r' 4\n",
    "    [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],# 'c' 5\n",
    "    [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],# 'f' 6\n",
    "    [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],# 'l' 7\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],# 'm' 8\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],# 'p' 9\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],# 's' 10\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],# 'o' 11\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],# 'n' 12\n",
    "   \n",
    "]\n",
    "\n",
    "encoding_size = len(char_encodings)\n",
    "\n",
    "index_to_char = [' ', 'a', 't', 'h', 'r', 'c', 'f', 'l', 'm', 'p', 's', 'o', 'n']\n",
    "\n",
    "char_to_int = {\n",
    "    ' ': 0,\n",
    "    'a': 1,\n",
    "    't': 2,\n",
    "    'h': 3,\n",
    "    'r': 4,\n",
    "    'c': 5,\n",
    "    'f': 6,\n",
    "    'l': 7,\n",
    "    'm': 8,\n",
    "    'p': 9,\n",
    "    's': 10,\n",
    "    'o': 11,\n",
    "    'n': 12\n",
    "}\n",
    "\n",
    "emoji_encodings = [\n",
    "    [1., 0., 0., 0., 0., 0., 0.], # hat\n",
    "    [0., 1., 0., 0., 0., 0., 0.], # rat\n",
    "    [0., 0., 1., 0., 0., 0., 0.], # cat\n",
    "    [0., 0., 0., 1., 0., 0., 0.], # flat\n",
    "    [0., 0., 0., 0., 1., 0., 0.], # matt\n",
    "    [0., 0., 0., 0., 0., 1., 0.], # cap\n",
    "    [0., 0., 0., 0., 0., 0., 1.], # son\n",
    "]\n",
    "\n",
    "emoji_encoding_size = len(emoji_encodings)\n",
    "\n",
    "index_to_emoji = [\"\\U0001F3A9\", \"\\U0001F400\", \"\\U0001F408\", \"\\U0001F3E2\", \"\\U0001F468\",\n",
    "                    \"\\U0001F9E2\", \"\\U0001F466\"]\n",
    "\n",
    "x_train = torch.tensor([\n",
    "    [[char_encodings[3]], [char_encodings[1]], [char_encodings[2]], [char_encodings[0]]], #'hat '\n",
    "    [[char_encodings[4]], [char_encodings[1]], [char_encodings[2]], [char_encodings[0]]], #'rat '\n",
    "    [[char_encodings[5]], [char_encodings[1]], [char_encodings[2]], [char_encodings[0]]], #'cat '\n",
    "    [[char_encodings[6]], [char_encodings[7]], [char_encodings[1]], [char_encodings[2]]], #'flat'\n",
    "    [[char_encodings[8]], [char_encodings[1]], [char_encodings[2]], [char_encodings[2]]], #'matt'\n",
    "    [[char_encodings[5]], [char_encodings[1]], [char_encodings[9]], [char_encodings[0]]], #'cap '\n",
    "    [[char_encodings[10]], [char_encodings[11]], [char_encodings[12]], [char_encodings[0]]],#'son '\n",
    "]) \n",
    "\n",
    "y_train = torch.tensor([\n",
    "    [emoji_encodings[0], emoji_encodings[0], emoji_encodings[0], emoji_encodings[0]],\n",
    "    [emoji_encodings[1], emoji_encodings[1], emoji_encodings[1], emoji_encodings[1]],\n",
    "    [emoji_encodings[2], emoji_encodings[2], emoji_encodings[2], emoji_encodings[2]],\n",
    "    [emoji_encodings[3], emoji_encodings[3], emoji_encodings[3], emoji_encodings[3]],\n",
    "    [emoji_encodings[4], emoji_encodings[4], emoji_encodings[4], emoji_encodings[4]],\n",
    "    [emoji_encodings[5], emoji_encodings[5], emoji_encodings[5], emoji_encodings[5]],\n",
    "    [emoji_encodings[6], emoji_encodings[6], emoji_encodings[6], emoji_encodings[6]],\n",
    "    \n",
    "])\n",
    "\n",
    "model = LongShortTermMemoryModel(encoding_size, emoji_encoding_size)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), 0.001)\n",
    "for epoch in range(500):\n",
    "    for i in range(x_train.size()[0]):\n",
    "        model.reset()\n",
    "        model.loss(x_train[i], y_train[i]).backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def find_emoji(word):\n",
    "    word_seq = []\n",
    "    model.reset()\n",
    "    for char in word:\n",
    "        word_seq.append(char_to_int[char])\n",
    "        \n",
    "    y = -1\n",
    "\n",
    "    for i in range(len(word_seq)):\n",
    "        y = model.f(torch.tensor([[char_encodings[word_seq[i]]]]))\n",
    "        \n",
    "    return index_to_emoji[y.argmax(1)]\n",
    "\n",
    "print(\"hat: {}\".format(find_emoji(\"hat\")))\n",
    "print(\"rat: {}\".format(find_emoji(\"rat\")))\n",
    "print(\"rt: {}\".format(find_emoji(\"rt\")))\n",
    "print(\"rats: {}\".format(find_emoji(\"rats\")))\n",
    "print(\"cap: {}\".format(find_emoji(\"cap\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5df70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
